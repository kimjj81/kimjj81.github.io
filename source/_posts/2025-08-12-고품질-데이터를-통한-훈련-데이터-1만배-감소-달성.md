---
title: 고품질 데이터를 통한 훈련 데이터 1만배 감소 달성
date: 2025-08-12 17:16:32
tags:
slug: reduce-training-data-by-10000x
---

[Achieving 10,000x training data reduction with high-fidelity labels](https://research.google/blog/achieving-10000x-training-data-reduction-with-high-fidelity-labels/?utm_source=chatgpt.com)

학습데이터를 1만배나 감소시켰다고 하니 눈이 안돌아갈 수 없습니다. +_+  

Notebook LLM 을 통한 요약 문서입니다.

요약의 요약을 하자면 데이터 큐레이션 프로세스가 가장 중요. 

- 큰 규모의 데이터를 LLM 을 통해 레이블링하고 클러스터로 구성 -> 인간 전문가가 "가장 정보성이 높고(혼돈하기 쉬운 예시 포함) 다양성이 있는" 소수의 예시에만 의견(레이블)을 제공하여 극단적으로 고품질의 데이터만 사용하여 훈련양 감소.  
- 광고처럼 변화가 빠른 도메인에서 새로운 유형의 안전하지 않은 콘텐츠 등장하여 개념 드리프트(concept drift)가 발생해도, 새로운 개념의 소수 데이터만 처리함으로써 빠르게 재훈련 가능.


## 상세 브리핑 문서: 고충실도 레이블을 통한 훈련 데이터 10,000배 감소 달성

이 브리핑 문서는 Google Ads의 Markus Krause와 Nancy Chang이 2025년 8월 7일에 발표한 "Achieving 10,000x training data reduction with high-fidelity labels"라는 새로운 연구 보고서의 주요 내용과 시사점을 다룹니다. 이 보고서는 대규모 언어 모델(LLM)을 미세 조정하는 데 필요한 훈련 데이터를 대폭 줄이는 새로운 능동 학습 방법을 제시합니다.

### 1. 주요 주제 및 핵심 아이디어

이 연구는 LLM 훈련의 주요 병목 현상 중 하나인 고품질 훈련 데이터의 필요성을 해결하는 데 중점을 둡니다. 핵심 아이디어는 적은 수의 고충실도(high-fidelity) 레이블이 많은 양의 저품질 레이블보다 훨씬 효율적일 수 있다는 것입니다.

  - 훈련 데이터 감소의 필요성: 광고 안전 콘텐츠 분류와 같은 복잡한 작업에 LLM을 활용하는 것은 효과적이지만, "정책 위반 콘텐츠를 식별하는 데 내재된 복잡성" 때문에 "필요한 품질과 규모로 큐레이션하기 어렵고 비용이 많이 드는 고충실도 훈련 데이터"가 필요합니다. 표준 데이터 집약적 접근 방식은 비용이 많이 들고, 특히 안전 정책이 진화하거나 새로운 유형의 안전하지 않은 광고 콘텐츠가 발생함에 따라 발생하는 개념 드리프트(concept drift)를 처리해야 할 때 더욱 그렇습니다. 따라서 "필요한 훈련 데이터의 양을 줄이는 것이 가장 중요합니다."
  - 능동 학습을 통한 데이터 큐레이션: 보고서는 "LLM 미세 조정에 필요한 훈련 데이터의 양을 대폭 줄이면서 인간 전문가와의 모델 정렬을 크게 개선할 수 있는 새롭고 확장 가능한 능동 학습을 위한 큐레이션 프로세스"를 설명합니다. 이 프로세스는 수천억 개의 예시가 있는 데이터 세트에 적용하여 "어떤 예시에 대한 주석이 가장 가치가 있을지 반복적으로 식별"하고 결과적으로 얻은 전문가 레이블을 미세 조정에 사용합니다.
  - 모델-인간 정렬 개선: 실험 결과, "훈련 데이터 규모를 100,000개에서 500개 미만의 훈련 예시로 줄일 수 있었으며, 동시에 인간 전문가와의 모델 정렬을 최대 65%까지 높였습니다." 생산 시스템에서는 "최대 4배 더 적은 데이터를 사용하면서도 품질을 유지하거나 개선"하는 등 더 큰 데이터 규모 감소를 보였습니다.
  - 접근 방식의 강점: 이 큐레이션 프로세스는 "문제 공간에 광범위한 그물을 던질 수 있는 LLM의 강점과 가장 어려운 예시에 더 효율적으로 집중할 수 있는 도메인 전문가의 강점"을 활용할 수 있습니다. "소수의 예시만으로 모델을 재훈련할 수 있는 능력은 광고 안전과 같이 빠르게 변화하는 도메인에서 특히 가치가 있습니다."

### 2. 가장 중요한 아이디어 또는 사실

  - 데이터 감소 규모: 이 연구의 가장 중요한 발견은 LLM 미세 조정을 위한 훈련 데이터 요구 사항을 "최대 4배(10,000배)"까지 줄일 수 있다는 것입니다. 실험에서는 100,000개에서 250~450개 예시로 줄였습니다.
  - 고충실도 레이블의 중요성: 데이터 양을 줄이면서도 성능을 유지하거나 개선하는 핵심은 "매우 높은 품질의 데이터"를 사용하는 것입니다. 연구자들은 "크라우드 소싱 데이터를 확실히 능가하려면 .8 쌍별 코헨의 카파(Cohen's Kappa) 이상의 레이블 품질이 필요하다"고 밝혔습니다.
  -큐레이션 프로세스:
    - 초기 모델 및 레이블링: "제로 샷 또는 소수 샷 초기 모델(LLM-0)"을 사용하여 대규모 레이블링된 데이터 세트를 생성합니다.
클러스터링 및 혼동 예시 식별: LLM이 레이블을 지정한 예시를 클러스터링하고, "클릭베이트와 양성 예시 사이의 잠재적인 모델 혼동을 나타내는" 겹치는 클러스터를 식별합니다.
    - 정보성 및 다양성: 이러한 겹치는 클러스터 쌍에서 "다른 레이블을 가진 가장 가까운 예시 쌍"을 찾고, "검색 공간의 더 넓은 영역을 포괄하는 쌍"을 우선시하여 인간 전문가에게 보냅니다. 이는 결과적으로 "정보성(결정 경계를 따라 가장 혼동하기 쉬운 예시를 포함하므로)과 다양성(해당 결정 경계의 다른 영역에서 가져오므로)"을 모두 갖춘 큐레이션 세트를 만듭니다.
    - 반복적 미세 조정: 전문가가 제공한 레이블을 사용하여 현재 모델을 평가하고 미세 조정하여 다음 모델을 생성합니다. 이 과정은 "모델-인간 정렬이 내부 정렬과 일치하거나 더 이상 개선될 수 없을 때까지" 반복됩니다.
  -코헨의 카파(Cohen's Kappa) 활용: 이 연구는 정답(ground truth)의 존재를 가정하지 않으므로, "표준 지표인 정밀도와 재현율(precision and recall)에 의존할 수 없습니다." 대신, "두 명의 독립적인 주석자가 우연히 동의하는 것 이상으로 얼마나 잘 정렬되는지에 대한 척도"인 코헨의 카파를 사용합니다. 0.8 이상의 카파 값은 "예외적으로 좋다"고 간주됩니다.
  - 실험 결과:
    - 데이터 규모 및 품질: 크라우드 소싱 데이터 세트는 각각 약 100K개의 주석을 가지고 있었고, 전문가 큐레이션 세트는 복잡성에 따라 250~450개의 누적 샘플을 사용했습니다. 전문가들의 평균 쌍별 코헨의 카파는 저복잡성 작업에서 0.81, 고복잡성 작업에서 0.78이었습니다. 크라우드 소싱 데이터의 전문가와의 정렬은 저복잡성에서 0.59, 고복잡성에서 0.41이었습니다.
  - 모델 성능:
    - 1.8B 파라미터 모델은 기본 모델과 큐레이션 모델 모두에서 유사한 성능을 보였습니다(카파 0.13~0.25).
    - 3.25B 파라미터 모델은 큐레이션 프로세스로 훈련했을 때 "상당한 품질 향상"을 보였습니다. 저복잡성 작업에서는 카파 점수가 0.36에서 0.56으로, 고복잡성 작업에서는 0.23에서 0.38로 향상되었습니다. 이는 "세 자릿수 더 적은 데이터(기본 조건의 100K에 비해 250~450개 예시)를 사용하면서 55~65%의 정렬 개선"을 의미합니다.
  - 향후 과제: 연구는 "충분한 레이블 품질이 주어지면" 이 큐레이션 프로세스가 효과적임을 입증했지만, "일관되게 이 수준의 품질을 달성하는 것은 별개의 도전 과제"이며, 이는 후속 블로그 게시물에서 다룰 예정입니다.

### 3. Google의 연구 철학 및 목표에 대한 시사점
이 연구는 Google Research의 전반적인 철학과 목표와 일치합니다.

  - 연구 철학: Google은 "다양한 시간 척도와 위험 수준에 걸쳐 다양한 유형의 연구에 도움이 되는 환경을 조성"하기 위해 노력합니다. 이 연구는 LLM 훈련의 실질적인 문제를 해결하고 효율성을 개선함으로써 이러한 철학을 구현합니다.
  - 영향 및 적용: Google은 "더 넓은 연구 커뮤니티와 정기적으로 오픈 소스 프로젝트를 공개하고 개발 사항을 Google 제품에 적용"합니다. 이 능동 학습 방법은 Google Ads에서 실제 문제를 해결하는 데 적용되었으며, 이는 연구 결과를 실제 제품에 적용하려는 Google의 의지를 보여줍니다.
  - 협력 및 지식 공유: Google은 "우리의 작업을 게시하여 아이디어를 공유하고 컴퓨터 과학 분야를 발전시키기 위해 협력적으로 작업"하는 것을 강조합니다. 이 보고서는 이러한 원칙을 반영합니다. 또한 "학생 프로그램", "교수 프로그램", "컨퍼런스 및 이벤트"를 통해 광범위한 연구 커뮤니티와의 협력을 장려합니다.
  - 연구 분야와의 연관성: 이 연구는 Google Research의 여러 핵심 연구 분야와 관련이 있습니다.
  - 기초 ML 및 알고리즘: "알고리즘 및 이론", "데이터 마이닝 및 모델링", "머신 인텔리전스", "자연어 처리"에 해당합니다.
  - 컴퓨팅 시스템 및 양자 AI: "로봇 공학"과 간접적으로 관련될 수 있는 실제 시스템 적용의 측면을 포함합니다.
  - 과학, AI 및 사회: "보안, 프라이버시 및 남용 방지(Security, Privacy & Abuse Prevention)" 및 "책임 있는 AI(Responsible AI)"와 직접적으로 관련되어 있으며, 광고 안전 분류 문제의 사회적 중요성을 강조합니다.
  - 이 브리핑 문서는 고품질 훈련 데이터의 효율적인 큐레이션을 통해 LLM 미세 조정의 데이터 병목 현상을 해결하는 Google의 혁신적인 접근 방식을 요약합니다. 이 방법은 상당한 데이터 감소와 모델 성능 향상을 동시에 달성하여, 특히 빠르게 변화하는 영역에서 LLM 기반 시스템의 유연성과 효율성을 높일 수 있는 잠재력을 보여줍니다.

