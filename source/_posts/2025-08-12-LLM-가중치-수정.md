---
title: LLM 가중치 수정
date: 2025-08-12 16:32:48
tags: edit_weight, fine_tuning, llm, weight_editing
---

- 딥러닝 가중치 구조와 포맷을 처음 접하는 개발자
- 파인튜닝 전 단계로 모델 내부를 직접 제어해보고 싶은 연구자
- LLM의 **어휘 단위 의미 수정**에 관심 있는 개발자
- 가중치 수정과 RAG의 차이를 실감하고 싶은 AI 엔지니어


## 1. [weight_editing_tutorial.ipynb](../ipynb/edit_weight/weight_editing_tutorial.ipynb)

**주제:**  
가장 기초적인 **가중치 생성 → 저장/로드 → 직접 수정(Weight Editing)** 과정을 파이썬/PyTorch 코드로 단계별 학습.

**주요 내용:**
- `nn.Linear`, `nn.Embedding`에서 가중치 생성 방식 이해
- PyTorch `.pt/.pth` 저장, `safetensors`, `ONNX` 포맷 비교
- `torch.no_grad()`로 안전하게 가중치 편집하는 방법
- 편집 vs 파인튜닝 코드 비교
- 저장된 state_dict / safetensors 직접 수정
- 초보자를 위한 **보안·이식성·버전 관리** 체크리스트

---

## 2. [llm_embedding_weight_editing.ipynb](../ipynb/edit_weight/llm_embedding_weight_editing.ipynb)

**주제:**  
Hugging Face 토크나이저 + 모델을 이용해 **특정 토큰 임베딩 벡터를 직접 편집**하고,  
그 효과를 출력 비교 및 **RAG(검색결합생성)**와 대비.

**주요 내용:**
- Tiny GPT-2(`sshleifer/tiny-gpt2`) 로드 및 토크나이저 사용
- 특정 토큰 ID 확인 및 해당 임베딩 벡터 관찰
- 벡터에 작은 편향 주입 후 출력 변화 확인
- safetensors로 편집된 모델 저장/재로드
- **RAG 대비 실험:** 외부 문서 검색 → 프롬프트 결합 → 출력 생성

## 3. 가중치 수정 방법 추가 설명

| 구분 | 학습 기반 | 비학습 기반 |
|------|-----------|-------------|
| **데이터 요구** | 새로운 훈련 데이터 필수 | 훈련 데이터 불필요 |
| **계산 비용** | 높음 (GPU 집약적) | 낮음 (CPU 가능) |
| **시간 소요** | 시간~일 단위 | 분~시간 단위 |
| **메모리 사용** | 대용량 (훈련 시) | 상대적 소용량 |
| **성능 향상** | 실질적 능력 확장 | 효율성 최적화 중심 |
| **가역성** | 어려움 (원본 손실) | 용이함 (원본 보존) |
| **전문성 요구** | 머신러닝 지식 필요 | 상대적 단순 |

### 3.1. 학습 기반 가중치 수정 (Fine-tuning)

새로운 데이터를 사용하여 역전파 알고리즘으로 가중치를 학습하는 방법입니다.

#### 3.1.1. 주요 특징
- 새로운 훈련 데이터 필요
- 역전파(Backpropagation) 알고리즘 사용
- 손실 함수(Loss Function)를 최소화하는 방향으로 가중치 업데이트
- 모델의 지식과 능력을 실질적으로 확장

#### 3.1.2. 세부 방법들

##### 3.1.2.1. Full Fine-tuning
- 모든 가중치를 업데이트
- 최고 성능 달성 가능
- 막대한 계산 자원 필요

##### 3.1.2.2. LoRA (Low-Rank Adaptation)
- 기존 가중치 고정 + 작은 어댑터 행렬 학습
- 메모리 사용량 90% 이상 감소
- 성능 손실 최소화

##### 3.1.2.3. QLoRA (Quantized LoRA)
- LoRA + 양자화 결합
- 더욱 효율적인 메모리 사용
- 개인 GPU로도 대형 모델 파인튜닝 가능

##### 3.1.2.4. Adapter Tuning
- 각 레이어에 작은 어댑터 모듈 추가
- 원본 가중치 완전 보존
- 태스크별 어댑터 교체 가능

### 3.2. 비학습 기반 가중치 수정

#### 3.2.1. 주요 특징

- 새로운 훈련 데이터 불필요
- 수학적 알고리즘이나 휴리스틱 사용
- 계산 비용 상대적으로 낮음
- 모델 최적화나 배포 효율성 중심

#### 3.2.2. 비학습 기반 가중치 수정

- 학습 없이 가중치를 직접 조작

##### 3.2.2.1. Pruning (가지치기)
- 중요도가 낮은 가중치를 0으로 설정
- 모델 크기 축소 및 속도 향상
- Magnitude-based, Gradient-based 등 다양한 기준

##### 3.2.2.2. Quantization (양자화)
- 32비트 가중치를 8비트, 4비트로 압축
- 메모리 사용량 대폭 감소
- INT8, INT4, Binary 등 다양한 정밀도

##### 3.2.2.3. Model Merging
- 여러 모델의 가중치를 가중평균으로 결합
- 특수화된 모델들의 능력 통합
- SLERP, TIES 등 고급 병합 기법

##### 3.2.2.4. Weight Interpolation
- 두 모델 간 가중치를 선형 보간
- 점진적 모델 변환 가능
- 모델 앙상블 효과

### 3.3 목적별 선택 가이드

#### 3.3.1. 학습 기반을 선택해야 하는 경우
- 새로운 도메인이나 태스크에 모델 적응
- 특정 스타일이나 톤으로 응답 변경
- 새로운 지식이나 능력 추가
- 모델의 근본적 행동 변경

#### 3.3.2. 비학습 기반을 선택해야 하는 경우
- 모델 크기나 속도 최적화
- 배포 환경의 제약 해결
- 여러 모델의 능력 통합
- 빠른 실험이나 프로토타이핑

### 3.4. 실제 활용 시나리오

#### 3.4.1. 기업 환경
1. **도메인 특화**: LoRA로 의료/법률 등 전문 분야 파인튜닝
2. **배포 최적화**: Quantization으로 모바일/엣지 배포
3. **다국어 지원**: Model Merging으로 언어별 모델 통합

#### 3.4.2. 개인/연구 환경
1. **리소스 제약**: QLoRA로 개인 GPU 활용
2. **빠른 실험**: Pruning으로 경량 모델 생성
3. **창작 활동**: 스타일 특화 파인튜닝

두 방법은 상호 보완적이며, 실제로는 조합해서 사용하는 경우가 많습니다. 예를 들어, LoRA 파인튜닝 후 Quantization으로 배포 최적화하는 방식입니다.

------
GPT-5, Claude-4 를 통해 생성된 문서를 수정