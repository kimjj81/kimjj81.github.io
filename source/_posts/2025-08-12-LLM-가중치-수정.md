---
title: LLM 가중치 수정
date: 2025-08-12 16:32:48
tags: edit_weight, fine_tuning, llm, weight_editing
---

- 딥러닝 가중치 구조와 포맷을 처음 접하는 개발자
- 파인튜닝 전 단계로 모델 내부를 직접 제어해보고 싶은 연구자
- LLM의 **어휘 단위 의미 수정**에 관심 있는 개발자
- 가중치 수정과 RAG의 차이를 실감하고 싶은 AI 엔지니어

## 1. [weight_editing_tutorial.ipynb](../ipynb/edit_weight/weight_editing_tutorial.ipynb)

**주제:**  
가장 기초적인 **가중치 생성 → 저장/로드 → 직접 수정(Weight Editing)** 과정을 파이썬/PyTorch 코드로 단계별 학습.

**주요 내용:**
- `nn.Linear`, `nn.Embedding`에서 가중치 생성 방식 이해
- PyTorch `.pt/.pth` 저장, `safetensors`, `ONNX` 포맷 비교
- `torch.no_grad()`로 안전하게 가중치 편집하는 방법
- 편집 vs 파인튜닝 코드 비교
- 저장된 state_dict / safetensors 직접 수정
- 초보자를 위한 **보안·이식성·버전 관리** 체크리스트

---

## 2. [llm_embedding_weight_editing.ipynb](../ipynb/edit_weight/llm_embedding_weight_editing.ipynb)

**주제:**  
Hugging Face 토크나이저 + 모델을 이용해 **특정 토큰 임베딩 벡터를 직접 편집**하고,  
그 효과를 출력 비교 및 **RAG(검색결합생성)**와 대비.

**주요 내용:**
- Tiny GPT-2(`sshleifer/tiny-gpt2`) 로드 및 토크나이저 사용
- 특정 토큰 ID 확인 및 해당 임베딩 벡터 관찰
- 벡터에 작은 편향 주입 후 출력 변화 확인
- safetensors로 편집된 모델 저장/재로드
- **RAG 대비 실험:** 외부 문서 검색 → 프롬프트 결합 → 출력 생성
