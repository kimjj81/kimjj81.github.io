---
title: RAG 질의 확장과 재순위화
date: 2025-06-13 11:03:00
tags: RAG, query, re-ranking, 
---


질의 확장(Query Expansion), `재순위화(Re-ranking)`은 RAG (Retrieval-Augmented Generation) 시스템에서 검색 정확도와 관련 응답 품질을 높이기 위해 사용됨

⸻

🔍 1. 질의 확장 (Query Expansion)

✅ 정의

`사용자의 원래 질의(Query)`를 더 풍부한 의미를 가진 형태로 `확장(augmentation)`하여 `검색 성능(Recall/Precision)`을 높이기 위한 기법입니다.

✅ 목적
	•	동의어, 유의어, 관련 개념 등을 추가함으로써 더 많은 관련 문서나 정보를 검색할 수 있도록 함.
	•	질의가 너무 짧거나 모호할 때 검색 성능 향상.

✅ 방법 종류


|방법|설명|예시|
|----------|:-------------:|:------|
|동의어 기반 확장|WordNet 등 사용|car → automobile|
|임베딩 기반 유사어 확장|Word2Vec, BERT 임베딩을 이용해 유사 단어 검색|laptop → notebook|
|LLM 기반 질의 재작성|GPT 등으로 자연어로 질의 재작성|"How to fix Macbook?" → "What are common solutions for Macbook hardware issues?"|
|사용자 로그 기반 확장|과거 검색/클릭 이력 기반 추천|"apple" → "apple fruit", "apple inc." 구분|

✅ RAG에서의 활용
	•	검색 파이프라인 이전 단계에서 query → expanded queries로 확장 후 각각에 대해 벡터 검색 수행
	•	Recall 향상 목적 → 더 많은 후보 문서를 회수

⸻

🧠 2. 재순위화 (Re-ranking)

✅ 정의

초기 검색 단계(Retriever)에서 얻은 문서 후보들을 정확도(Precision) 기준으로 다시 정렬하는 후처리 단계입니다.

✅ 목적
	•	`초기 검색(보통 BM25, 벡터 검색)`은 빠르지만 정확도가 낮을 수 있음
	•	후보 중 LLM이나 랭킹 모델을 통해 더 적합한 문서를 위로 올림

✅ 방법 종류


* BM25 + BERT ranker
    - BM25로 검색 → BERT 기반 CrossEncoder로 유사도 재계산	
* ColBERT
    - 토큰 수준으로 질의-문서간 연산하여 정교하게 점수화	
* LLM Scoring
	- GPT에 “질문과 문서 중 얼마나 관련 있는가?”를 직접 평가하도록 지시	
* Semantic Matching + Rule
    - 특정 키워드 포함 여부, 문서 길이 등을 조건으로 보정	

✅ RAG에서의 활용
* Retriever → top-k candidates 중에서 Re-ranker가 다시 top-k를 결정
* 최종적으로 LLM에 넣는 문서 순서를 조정 → 응답 품질 향상

⸻

🎯 요약

|기술|목적|방법|RAG 파이프라인 내 위치|
|----------|-------------|------|------|
|질의 확장|Recall 향상|동의어, 임베딩, LLM 기반 질의 재작성|검색 전|
|재순위화|Precision 향상|BERT, ColBERT, LLM scoring|검색 후|


⸻

📌 예시 워크플로우 (하이브리드)
1.	사용자가 "청바지 추천" 질의
2.	질의 확장 → "청바지 추천", "데님 바지 추천", "남성용 청바지"
3.	각 질의로 vector 검색 → top 30 문서 회수
4.	Re-ranking → GPT나 CrossEncoder로 relevance 점수 부여
5.	상위 5개 문서 LLM에 전달 → 답변 생성

⸻
