---
title: Transformer
tags:
---

https://poloclub.github.io/transformer-explainer/


## 트랜스포머와 LLM 기반 임베딩 알고리즘 차이에 대한 설명 및 적합한 임베딩 알고리즘 추천

` 질문 : 트랜스포머와 llm 기반은 무슨 차이가 있나요? 트랜스포머도 ml 계열이 아닌가요? `

`1. 트랜스포머와 LLM의 관계 및 오해 해소`

트랜스포머(Transformer)는 `신경망 아키텍처`의 한 종류이고, LLM(Large Language Model, 거대 언어 모델)은 `트랜스포머 아키텍처를 기반으로 만들어진 모델`입니다.  트랜스포머는 마치 건물을 짓는 '설계도'이고, LLM은 그 설계도에 따라 실제로 지어진 '건물'이라고 생각하시면 이해하기 쉽습니다.

*   `트랜스포머 (Transformer):`  2017년 구글에서 발표한 신경망 아키텍처로, 어텐션 메커니즘을 사용하여 문장 내 단어 간의 관계를 효과적으로 파악합니다.  RNN의 단점을 극복하고 병렬 처리가 가능하여 학습 속도가 빠릅니다.  기계 번역, 텍스트 요약 등 다양한 자연어 처리 작업에 적용됩니다.  LLM의 `기반` 기술입니다.
*   `LLM (Large Language Model):`  트랜스포머 아키텍처를 기반으로 `매우 큰 규모의 데이터셋으로 학습된` 언어 모델입니다.  GPT, BERT, PaLM 등이 대표적인 예시입니다.  문맥을 이해하고 생성하는 능력이 뛰어나 텍스트 생성, 질문 답변, 번역, 코딩 등 다양한 작업을 수행할 수 있습니다. 트랜스포머 구조를 사용하지만, 모델의 크기(파라미터 수)와 학습 데이터량이 훨씬 방대합니다.

네, 트랜스포머도 머신러닝(ML) 계열이 맞습니다.  딥러닝은 머신러닝의 한 종류이고, 트랜스포머는 딥러닝 모델입니다.

`2. 사용자의 질문에 적합한 임베딩 알고리즘 추천`

사용자님의 질문은 트랜스포머와 LLM의 기본적인 차이점을 이해하는 데 초점이 맞춰져 있으므로, `이론적인 배경 이해를 돕는 방향`으로 추천드리겠습니다.

*   `Word2Vec 또는 GloVe:`  단어 임베딩의 기본 원리를 이해하기에 좋습니다.  단어 간의 유사도를 벡터 공간에서 표현하는 방법을 직관적으로 보여줍니다.  트랜스포머와 LLM에 비해 훨씬 간단하므로, 기본 개념을 먼저 익히기에 적합합니다.
    *   `이유:`  단어 임베딩의 기본 개념을 쉽게 이해할 수 있으며, 트랜스포머 기반 임베딩과의 차이점을 명확하게 파악하는 데 도움이 됩니다.

*   `BERT (또는 KoBERT):`  트랜스포머 아키텍처를 기반으로 구축된 대표적인 LLM입니다. BERT를 직접 사용해보고, 사전 학습된 모델의 성능을 확인해보면 트랜스포머의 강력함을 체감할 수 있습니다.
    *   `이유:`  트랜스포머 아키텍처를 직접 경험하고, LLM의 작동 방식을 이해하는 데 도움이 됩니다. 사전 학습된 모델을 사용하면, 간단한 실험을 통해 LLM의 성능을 확인할 수 있습니다.

*   `(선택 사항) Sentence-BERT:`  문장 임베딩을 위한 모델로, BERT를 기반으로 문장 수준의 의미를 파악하도록 튜닝되었습니다.  문장 유사도 비교, 의미 검색 등에 활용할 수 있습니다.
    *   `이유:`  문장 수준의 의미를 벡터 공간에 표현하는 방법을 이해하고, 다양한 자연어 처리 작업에 적용하는 데 도움이 됩니다. BERT와 함께 사용하면, 단어와 문장 임베딩의 관계를 더욱 명확하게 파악할 수 있습니다.

`결론:`

먼저 Word2Vec 또는 GloVe를 통해 단어 임베딩의 기본 원리를 이해하고, BERT를 사용하여 트랜스포머 아키텍처와 LLM의 작동 방식을 직접 경험해보시는 것을 추천합니다. 이를 통해 트랜스포머와 LLM의 차이점을 명확하게 이해하고, 다양한 임베딩 알고리즘을 선택하고 활용하는 데 도움이 될 것입니다. Sentence-BERT는 선택적으로 추가하여 문장 임베딩에 대한 이해를 넓힐 수 있습니다.