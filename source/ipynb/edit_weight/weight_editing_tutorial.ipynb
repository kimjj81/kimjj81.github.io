{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45228eb6",
   "metadata": {},
   "source": [
    "\n",
    "# Weight Editing 101 — From First Weights to Direct Editing (PyTorch)\n",
    "\n",
    "이 노트북은 **가중치(Weights)가 어떻게 생성되고, 어떤 파일 포맷으로 저장/로드하며, 어떻게 직접 수정(Weight Editing)하는지**를 단계별로 보여줍니다.  \n",
    "또한 **파인튜닝(Fine-tuning)**과의 차이를 코드 레벨에서 비교하고, 초보자가 실무에서 주의할 점을 체크리스트로 정리합니다.\n",
    "\n",
    "> 실행 환경 메모: `safetensors`, `onnx`, `onnxruntime`이 설치되어 있지 않을 수도 있습니다.  \n",
    "> 이 노트북은 해당 라이브러리가 없으면 **자동으로 해당 섹션을 건너뛰고** 계속 진행합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388469ad",
   "metadata": {},
   "source": [
    "## 0) 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf3e446",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys, platform, importlib\n",
    "print(f\"Python: {sys.version}\")\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "\n",
    "# 필수: PyTorch\n",
    "try:\n",
    "    import torch, torch.nn as nn, torch.optim as optim\n",
    "    TORCH_OK = True\n",
    "    print(\"PyTorch import: OK\")\n",
    "except Exception as e:\n",
    "    TORCH_OK = False\n",
    "    print(\"PyTorch import: FAILED:\", e)\n",
    "\n",
    "# 선택: safetensors\n",
    "try:\n",
    "    from safetensors.torch import save_file as safetensors_save_file, load_file as safetensors_load_file\n",
    "    SAFETENSORS_OK = True\n",
    "    print(\"safetensors import: OK\")\n",
    "except Exception as e:\n",
    "    SAFETENSORS_OK = False\n",
    "    print(\"safetensors import: not available\")\n",
    "\n",
    "# 선택: ONNX & onnxruntime\n",
    "try:\n",
    "    import onnx\n",
    "    import torch.onnx as to_onnx\n",
    "    ONNX_OK = True\n",
    "    print(\"onnx import: OK\")\n",
    "except Exception as e:\n",
    "    ONNX_OK = False\n",
    "    print(\"onnx import: not available\")\n",
    "\n",
    "try:\n",
    "    import onnxruntime as ort\n",
    "    ONNXRUNTIME_OK = True\n",
    "    print(\"onnxruntime import: OK\")\n",
    "except Exception as e:\n",
    "    ONNXRUNTIME_OK = False\n",
    "    print(\"onnxruntime import: not available\")\n",
    "\n",
    "if TORCH_OK:\n",
    "    torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51cfcf8",
   "metadata": {},
   "source": [
    "\n",
    "## 1) “가중치가 만들어지는” 가장 기초\n",
    "\n",
    "`nn.Linear` 같은 레이어는 생성 시 **무작위 초기화**로 가중치/바이어스를 만듭니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be828e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if not TORCH_OK:\n",
    "    raise RuntimeError(\"PyTorch가 필요합니다. 위 셀의 PyTorch import가 실패했습니다.\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# 입력 4 → 출력 3\n",
    "layer = nn.Linear(in_features=4, out_features=3, bias=True)\n",
    "\n",
    "print(\"W shape:\", layer.weight.shape)  # [3, 4]\n",
    "print(\"b shape:\", layer.bias.shape)    # [3]\n",
    "\n",
    "x = torch.randn(1, 4)\n",
    "y = layer(x)\n",
    "print(\"sample input:\", x)\n",
    "print(\"y:\", y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e3b4d0",
   "metadata": {},
   "source": [
    "\n",
    "## 2) 가중치 파일 포맷과 저장/불러오기\n",
    "\n",
    "### 2.1 PyTorch 표준 (`.pt`/`.pth`; Pickle 기반)\n",
    "- 일반적으로 **`state_dict`**만 저장/로드하는 것이 권장됩니다.\n",
    "- Pickle 기반이라 **신뢰할 수 있는 파일만 로드**하세요.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77486d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "\n",
    "# 저장 (state_dict 권장)\n",
    "torch.save(layer.state_dict(), \"/mnt/data/linear_state.pt\")\n",
    "print(\"Saved: /mnt/data/linear_state.pt\")\n",
    "\n",
    "# 동일 구조의 새 레이어에 로드\n",
    "layer2 = nn.Linear(4, 3, bias=True)\n",
    "state_loaded = torch.load(\"/mnt/data/linear_state.pt\", map_location=\"cpu\")\n",
    "layer2.load_state_dict(state_loaded)\n",
    "\n",
    "# 일치 여부 대략 확인\n",
    "with torch.no_grad():\n",
    "    diff = (layer.weight - layer2.weight).abs().max().item()\n",
    "print(\"Max weight diff between layer & layer2:\", diff)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4ee701",
   "metadata": {},
   "source": [
    "\n",
    "### 2.2 `safetensors` (보안/속도/무시리얼라이즈 장점)\n",
    "- pickle이 아니므로 **안전한 배포/공유**에 유리합니다.\n",
    "- 없으면 자동으로 건너뜁니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25147ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if SAFETENSORS_OK:\n",
    "    safetensors_save_file(layer.state_dict(), \"/mnt/data/linear_state.safetensors\")\n",
    "    print(\"Saved: /mnt/data/linear_state.safetensors\")\n",
    "\n",
    "    st = safetensors_load_file(\"/mnt/data/linear_state.safetensors\")\n",
    "    layer3 = nn.Linear(4, 3, bias=True)\n",
    "    layer3.load_state_dict(st)\n",
    "    with torch.no_grad():\n",
    "        diff = (layer.weight - layer3.weight).abs().max().item()\n",
    "    print(\"Max weight diff between layer & layer3:\", diff)\n",
    "else:\n",
    "    print(\"safetensors unavailable — skipping this section.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcb83f1",
   "metadata": {},
   "source": [
    "\n",
    "### 2.3 ONNX (모델 구조 + 가중치를 그래프로 내보내기)\n",
    "- `onnx`와 `onnxruntime`이 모두 있을 때 예제를 실행합니다.\n",
    "- 보통은 **PyTorch에서 수정 → ONNX로 재내보내기**가 현실적입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcef743",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if ONNX_OK:\n",
    "    import torch.onnx as to_onnx\n",
    "    dummy = torch.randn(1, 4)\n",
    "    to_onnx.export(\n",
    "        layer, dummy, \"/mnt/data/linear.onnx\",\n",
    "        input_names=[\"x\"], output_names=[\"y\"], opset_version=17\n",
    "    )\n",
    "    print(\"Exported: /mnt/data/linear.onnx\")\n",
    "\n",
    "    if ONNXRUNTIME_OK:\n",
    "        sess = ort.InferenceSession(\"/mnt/data/linear.onnx\", providers=[\"CPUExecutionProvider\"])\n",
    "        out = sess.run([\"y\"], {\"x\": dummy.numpy()})[0]\n",
    "        print(\"onnxruntime output shape:\", out.shape)\n",
    "    else:\n",
    "        print(\"onnxruntime not available — cannot run inference here.\")\n",
    "else:\n",
    "    print(\"onnx unavailable — skipping ONNX export.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcc2b0b",
   "metadata": {},
   "source": [
    "\n",
    "## 3) 가중치를 **직접** 수정 (Weight Editing)\n",
    "\n",
    "> 옵티마이저/학습 없이 **텐서 값을 직접 변경**하는 행위입니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184a3bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3.1 선형 레이어의 특정 행/열 덮어쓰기\n",
    "with torch.no_grad():\n",
    "    # 첫 번째 출력 뉴런의 가중치를 모두 0으로\n",
    "    layer.weight[0, :] = 0.0\n",
    "    # 바이어스도 원하는 값으로\n",
    "    layer.bias[0] = 1.0\n",
    "\n",
    "print(\"Edited weight[0]:\", layer.weight[0])\n",
    "print(\"Edited bias[0]:\", layer.bias[0])\n",
    "\n",
    "# 3.2 임베딩에서 특정 토큰 벡터 수정 (LLM 임베딩 편집의 축소판)\n",
    "emb = nn.Embedding(num_embeddings=10, embedding_dim=5)\n",
    "token_id = 3\n",
    "print(\"원래 임베딩(토큰 3):\", emb.weight[token_id])\n",
    "\n",
    "with torch.no_grad():\n",
    "    new_vec = torch.tensor([1.0, -1.0, 0.5, 0.5, 0.0])\n",
    "    emb.weight[token_id] = new_vec\n",
    "\n",
    "print(\"수정 후 임베딩(토큰 3):\", emb.weight[token_id])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d904cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3.3 저랭크 업데이트 아이디어 흉내(LoRA 느낌)\n",
    "W = layer.weight.data           # [out, in]\n",
    "rank = 1\n",
    "A = torch.randn(W.size(0), rank)\n",
    "B = torch.randn(W.size(1), rank)\n",
    "delta = A @ B.t()\n",
    "\n",
    "with torch.no_grad():\n",
    "    layer.weight += 0.01 * delta\n",
    "\n",
    "print(\"Applied small low-rank delta to layer.weight\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0d84a5",
   "metadata": {},
   "source": [
    "\n",
    "## 4) “가중치 수정” vs “파인튜닝(학습)” 비교 (코드 관점)\n",
    "- **편집**: 목적함수 없이 즉각적 변경 — 빠르지만 예측 불가.\n",
    "- **파인튜닝**: 손실함수/데이터로 체계적 업데이트 — 안정적·재현 가능.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406fd451",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4.1 (편집) 수동 변경\n",
    "with torch.no_grad():\n",
    "    noise = 0.001 * torch.randn_like(layer.weight)\n",
    "    layer.weight += noise\n",
    "print(\"Weight edited with small random noise (no optimizer)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e43f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4.2 (학습) 미니 배치 파인튜닝\n",
    "model = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 3))\n",
    "opt = optim.Adam(model.parameters(), lr=1e-2)\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "\n",
    "x = torch.randn(32, 4)\n",
    "target = torch.randn(32, 3)\n",
    "\n",
    "model.train()\n",
    "for step in range(20):\n",
    "    opt.zero_grad()\n",
    "    pred = model(x)\n",
    "    loss = loss_fn(pred, target)\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    if step % 5 == 0:\n",
    "        print(f\"step {step:02d} | loss {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5252387b",
   "metadata": {},
   "source": [
    "\n",
    "## 5) 저장된 가중치 파일을 **편집**해서 다시 쓰기\n",
    "\n",
    "### 5.1 PyTorch `state_dict` 편집\n",
    "- 키 이름을 확인하고, 원하는 텐서를 수정한 뒤 다시 저장합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce044a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "state = torch.load(\"/mnt/data/linear_state.pt\", map_location=\"cpu\")\n",
    "print(\"Keys in state_dict:\", list(state.keys()))\n",
    "\n",
    "# 예: weight의 첫 행을 0으로\n",
    "with torch.no_grad():\n",
    "    state[\"weight\"][0] = 0.0\n",
    "\n",
    "torch.save(state, \"/mnt/data/linear_state_edited.pt\")\n",
    "print(\"Saved edited state_dict to: /mnt/data/linear_state_edited.pt\")\n",
    "\n",
    "# 주입 테스트\n",
    "layer_edited = nn.Linear(4, 3, bias=True)\n",
    "layer_edited.load_state_dict(torch.load(\"/mnt/data/linear_state_edited.pt\", map_location=\"cpu\"))\n",
    "print(\"Loaded edited state into new layer.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cc3c58",
   "metadata": {},
   "source": [
    "\n",
    "### 5.2 `safetensors` 편집\n",
    "- 텐서만 담겨 있으므로 키와 shape을 정확히 알고 있어야 합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8832063",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if SAFETENSORS_OK:\n",
    "    st = safetensors_load_file(\"/mnt/data/linear_state.safetensors\")\n",
    "    print(\"Keys:\", list(st.keys()))\n",
    "    with torch.no_grad():\n",
    "        st[\"weight\"][1] += 0.123  # 두 번째 행에 상수 더하기\n",
    "    safetensors_save_file(st, \"/mnt/data/linear_state_edited.safetensors\")\n",
    "    print(\"Saved: /mnt/data/linear_state_edited.safetensors\")\n",
    "\n",
    "    layer_edited2 = nn.Linear(4, 3, bias=True)\n",
    "    layer_edited2.load_state_dict(safetensors_load_file(\"/mnt/data/linear_state_edited.safetensors\"))\n",
    "    print(\"Loaded edited safetensors into new layer.\")\n",
    "else:\n",
    "    print(\"safetensors unavailable — skipping edit example.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4629a6b9",
   "metadata": {},
   "source": [
    "\n",
    "## 6) ONNX 가중치 직접 편집에 관하여\n",
    "\n",
    "- ONNX는 가중치를 **initializer**로 그래프에 포함합니다. 직접 편집은 가능하지만 번거롭습니다.\n",
    "- 일반적으로 **PyTorch에서 편집 → ONNX로 재-export**가 현실적인 워크플로입니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbd3793",
   "metadata": {},
   "source": [
    "\n",
    "## 7) 실무 체크리스트 (초보자 필수)\n",
    "\n",
    "- **state_dict 저장 권장**: `torch.save(model.state_dict(), path)`  \n",
    "  전체 모델 저장은 코드 의존·보안 이슈로 지양.\n",
    "- **Pickle 보안**: `.pt/.pth`는 pickle 기반 → **신뢰 가능한 파일만 로드**. 배포/교차 조직 공유에는 **safetensors 권장**.\n",
    "- **`torch.no_grad()`**: 수동 편집 시 그래프 오염/메모리 낭비 방지.\n",
    "- **정밀도(dtype)**: fp32/fp16/bf16/int8/int4 등 경량화는 정확도 트레이드오프. 벤치마크 필수.\n",
    "- **`model.eval()`**: 추론 시 드롭아웃/BatchNorm 고정.\n",
    "- **키/shape 검증**: `load_state_dict(..., strict=True)`로 안전하게. 불가피할 때만 `strict=False`.\n",
    "- **버전 고정**: 프레임워크/커스텀 코드 버전 차이로 로드 실패 가능 → `requirements.txt` 및 커밋 해시 관리.\n",
    "- **대형 모델 편집 리스크**: 작은 편집도 광범위한 부작용 가능 → **카나리아 테스트/가드레일/회귀 테스트** 필수.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594e9c24",
   "metadata": {},
   "source": [
    "\n",
    "## 8) 요약\n",
    "\n",
    "- **가중치 수정(Weight Editing)**: 학습 없이 텐서 값을 직접 바꾸는 것 → 빠르지만 예측 불가.\n",
    "- **파인튜닝**: 데이터/손실함수로 체계적으로 업데이트 → 안정적·재현 가능.\n",
    "- **RAG**: 가중치를 건드리지 않고 검색 결과를 프롬프트에 주입 → 최신성/소유 데이터 반영에 유리.\n",
    "- 파일 포맷은 **state_dict(PyTorch)**가 기본, 공유/배포에는 **safetensors**가 안전, 배포용 런타임에는 **ONNX**가 유용.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
